{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Que 1. What is Ensemble Learning in machine learning? Explain the key idea behind it.\n",
        "- Ensemble learning combines multiple individual machine learning models (weak learners) to create a single, stronger, and more accurate predictive model, leveraging the \"wisdom of the crowd\" principle where diverse perspectives reduce overall errors and improve robustness against overfitting. The key idea is that by aggregating predictions from various models, the errors or biases of individual models get compensated by others, leading to a more reliable and stable outcome than any single model could achieve."
      ],
      "metadata": {
        "id": "lCt32xCHl6TH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que 2. What is the difference between Bagging and Boosting?\n",
        "- Bagging (Bootstrap Aggregating) trains many models in parallel on random data subsets to reduce variance (overfitting), while Boosting trains models sequentially, with each new model correcting errors of the previous one to reduce bias (underfitting), effectively turning weak learners into strong ones.\n",
        "\n",
        "- Bagging uses averaging/voting (e.g., Random Forest), runs in parallel, and handles outliers well, whereas Boosting uses weighted errors (e.g., AdaBoost, XGBoost), runs sequentially, and is more sensitive to noise.\n",
        "\n",
        "- Bagging is best for high-variance, complex models (e.g., deep trees) that tend to overfit, whereas Boosting is best for high-bias, simple models (e.g., shallow trees) that underfit.\n",
        "\n"
      ],
      "metadata": {
        "id": "hCEBOPjgxD2M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: What is bootstrap sampling and what role does it play in Bagging methods like Random Forest?\n",
        "- Bootstrap sampling creates diverse training sets for bagging by resampling original data with replacement, allowing duplicates and omissions, which trains varied base models (like decision trees) to reduce variance and overfitting, leading to more robust predictions when aggregated (averaged/voted) in methods like Random Forests. It's the core of Bagging (Bootstrap Aggregation), enabling models to generalize better by reducing reliance on any single data point, a key step in creating powerful ensembles.\n",
        "\n",
        "- It creates multiple unique training subsets (bootstrap samples) from one original dataset, then trains a separate, often simple, base model (e.g., a decision tree) on each unique bootstrap sample. It reduces overfitting because each model sees a slightly different dataset, they learn different patterns, preventing them from becoming too specialized (overfitting) to the original data. It aggregates predictions by combining the predictions from all base models (e.g., majority vote for classification, averaging for regression) to produce a more stable and accurate final prediction.\n"
      ],
      "metadata": {
        "id": "YurvkadVyhYC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que 4. What are Out-of-Bag (OOB) samples and how is OOB score used to\n",
        "evaluate ensemble models?\n",
        "- Out-of-Bag (OOB) samples are data points not included in the bootstrap sample used to train a specific base model (like a decision tree) in an ensemble method (e.g., Random Forest). The OOB score evaluates the model's performance by using these left-out samples for internal validation, providing an unbiased estimate of generalization error without needing a separate validation set, much like cross-validation but inherent to the bagging process, as these samples were never seen during training.\n",
        "\n",
        "- For each data point in the original dataset, it's passed through all the base models (trees) for which it was not used in training (i.e., the OOB trees). The predictions from these OOB trees are aggregated (e.g., by majority vote for classification) to get a final prediction for that data point. The final prediction is compared to the actual true value, and the error (or accuracy) is calculated across all data points. This aggregated error rate is the OOB score (or error), serving as a reliable, internal validation metric that estimates how well the final ensemble model will perform on unseen data, similar to a hold-out set but without the need to split the data beforehand."
      ],
      "metadata": {
        "id": "Fc-JmcBw0mPL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que 5. Compare feature importance analysis in a single Decision Tree vs. a Random Forest.\n",
        "- **Feature Importance in a Single Decision Tree :**\n",
        "    - In a single decision tree, feature importance is determined by how much each feature reduces the impurity (e.g., Gini impurity or entropy) of the nodes it splits. The importance of a feature is often calculated as the total reduction in impurity across all splits made using that feature, weighted by the number of samples affected by each split.\n",
        "\n",
        "    - **Characteristics :**\n",
        "        - The importance scores are highly sensitive to the specific training data and small changes can lead to different tree structures and vastly different feature rankings.\n",
        "\n",
        "        - It provides a localized view of feature usage within one specific tree structure, which might be optimal for that single instance but not generalizable.\n",
        "        - Trees can be biased towards selecting continuous or high-cardinality features.\n",
        "\n",
        "- **Feature Importance in a Random Forest :**\n",
        "    - A Random Forest, an ensemble of many decision trees, offers a more robust and stable measure of feature importance. The importance of a feature in a Random Forest is the average of its importance across all the individual decision trees in the forest. The final scores are often normalized so their sum is 1.\n",
        "\n",
        "    - **Characteristics :**\n",
        "        - By averaging across many trees built on different bootstrapped subsets of data and features, the measure becomes more stable and less dependent on random data fluctuations.\n",
        "\n",
        "        - It provides a global, aggregated view of the feature's contribution across the entire ensemble, which is generally more reliable and generalizable to unseen data.\n",
        "        - While some bias towards certain feature types still exists, the ensemble process helps mitigate the extreme biases seen in individual, unpruned trees."
      ],
      "metadata": {
        "id": "xlCpPPOM3H43"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 6: Write a Python program to:\n",
        "# Load the Breast Cancer dataset using - sklearn.datasets.load_breast_cancer()\n",
        "# Train a Random Forest Classifier\n",
        "# Print the top 5 most important features based on feature importance scores.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = load_breast_cancer()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "X = df\n",
        "y = data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
        "\n",
        "rfc = RandomForestClassifier(random_state=42)\n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "feature_importances = rfc.feature_importances_\n",
        "importance_series = pd.Series(feature_importances, index=X.columns)\n",
        "top_5_important_features = importance_series.sort_values(ascending=False).head(5)\n",
        "\n",
        "print(\"Top 5 most important features based on Random Forest:\")\n",
        "print(top_5_important_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xVjiUrv5wn2",
        "outputId": "81a2f8b7-feab-4053-cae1-98646c784dbf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 most important features based on Random Forest:\n",
            "mean concave points     0.141934\n",
            "worst concave points    0.127136\n",
            "worst area              0.118217\n",
            "mean concavity          0.080557\n",
            "worst radius            0.077975\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 7: Write a Python program to:\n",
        "# Train a Bagging Classifier using Decision Trees on the Iris dataset\n",
        "# Evaluate its accuracy and compare with a single Decision Tree\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "tree_classifier = DecisionTreeClassifier(random_state=42)\n",
        "tree_classifier.fit(X_train, y_train)\n",
        "y_pred_tree = tree_classifier.predict(X_test)\n",
        "accuracy_tree = accuracy_score(y_test, y_pred_tree)\n",
        "\n",
        "bagging_classifier = BaggingClassifier(estimator=DecisionTreeClassifier(random_state=42), n_estimators=10, random_state=42)\n",
        "bagging_classifier.fit(X_train, y_train)\n",
        "y_pred_bagging = bagging_classifier.predict(X_test)\n",
        "accuracy_bagging = accuracy_score(y_test, y_pred_bagging)\n",
        "\n",
        "print(f\"Accuracy of a single Decision Tree: {accuracy_tree:.4f}\")\n",
        "print(f\"Accuracy of Bagging Classifier: {accuracy_bagging:.4f}\")\n",
        "\n",
        "if accuracy_bagging > accuracy_tree:\n",
        "    print(\"\\nThe Bagging Classifier performed better than the single Decision Tree.\")\n",
        "elif accuracy_bagging < accuracy_tree:\n",
        "    print(\"\\nThe single Decision Tree performed better than the Bagging Classifier.\")\n",
        "else:\n",
        "    print(\"\\nBoth models performed equally well.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjZkIHlr8dv7",
        "outputId": "d1b55f3c-9276-4e60-8e8e-9bbb2c747530"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of a single Decision Tree: 1.0000\n",
            "Accuracy of Bagging Classifier: 1.0000\n",
            "\n",
            "Both models performed equally well.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 8: Write a Python program to:\n",
        "# Train a Random Forest Classifier\n",
        "# Tune hyperparameters max_depth and n_estimators using GridSearchCV\n",
        "# Print the best parameters and final accuracy\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "rfc = RandomForestClassifier()\n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "params = {\n",
        "    'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
        "    'n_estimators': [30, 40, 50, 100, 200, 300]\n",
        "}\n",
        "grid_search = GridSearchCV(rfc, param_grid=params, cv=5, verbose=0)\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(grid_search.best_params_)\n",
        "y_pred = grid_search.best_estimator_.predict(X_test)\n",
        "print(f'accuracy score : {accuracy_score(y_test, y_pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smVsbAjhBypt",
        "outputId": "c9b83197-bf63-4289-c4f5-824969d5e613"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'max_depth': 10, 'n_estimators': 100}\n",
            "accuracy score : 0.8666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 9: Write a Python program to:\n",
        "# Train a Bagging Regressor and a Random Forest Regressor on the California Housing dataset\n",
        "# Compare their Mean Squared Errors (MSE)\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "data = fetch_california_housing()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "X = df\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "rf_regressor = RandomForestRegressor(random_state=42)\n",
        "rf_regressor.fit(X_train, y_train)\n",
        "y_pred_rf = rf_regressor.predict(X_test)\n",
        "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
        "\n",
        "bagging_regressor = BaggingRegressor(estimator=DecisionTreeRegressor(random_state=42), n_estimators=10, random_state=42)\n",
        "bagging_regressor.fit(X_train, y_train)\n",
        "y_pred_bagging = bagging_regressor.predict(X_test)\n",
        "mse_bagging = mean_squared_error(y_test, y_pred_bagging)\n",
        "\n",
        "print(f'Mean Squared Error Of Random Forest Regressor: {mse_rf:.4f}')\n",
        "print(f'Mean Squared Error Of Bagging Regressor: {mse_bagging:.4f}')\n",
        "\n",
        "if mse_rf < mse_bagging:\n",
        "    print(\"\\nRandom Forest Regressor performed better (lower MSE).\")\n",
        "elif mse_bagging < mse_rf:\n",
        "    print(\"\\nBagging Regressor performed better (lower MSE).\")\n",
        "else:\n",
        "    print(\"\\nBoth regressors performed equally well (same MSE).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6eiCqj0M9E9",
        "outputId": "d57fd1b7-8286-4d05-ae93-0841201048d8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error Of Random Forest Regressor: 0.2565\n",
            "Mean Squared Error Of Bagging Regressor: 0.2862\n",
            "\n",
            "Random Forest Regressor performed better (lower MSE).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que 10. You are working as a data scientist at a financial institution to predict loan default. You have access to customer demographic and transaction history data.  \n",
        "You decide to use ensemble techniques to increase model performance.  \n",
        "Explain your step-by-step approach to:  \n",
        "1. Choose between Bagging or Boosting  \n",
        "2. Handle overfitting  \n",
        "3. Select base models  \n",
        "4. Evaluate performance using cross-validation  \n",
        "5. Justify how ensemble learning improves decision-making in this real-world\n",
        "context.\n",
        "\n",
        "#Answer.\n",
        "- **1. Choose between Bagging or Boosting :**\n",
        "    - Start with boosting for potentially higher accuracy on complex financial data, but use bagging if overfitting becomes an issue or faster training is needed.\n",
        "    \n",
        "- **2. Handle Overfitting :**\n",
        "    - **Regularization:** Add L1/L2 penalties (common in boosting).\n",
        "    - **Early Stopping:** Monitor validation performance during boosting training and stop when it worsens.\n",
        "    - **Subsampling:** Use row (bootstrapping in bagging) or feature subsampling.\n",
        "    - **Hyperparameter Tuning:** Use Grid Search/Random Search for parameters like max_depth, n_estimators, learning_rate.\n",
        "- **3. Select Base Models :**\n",
        "    - **Tree-based Models:** Start with Decision Trees as base learners (for both).\n",
        "    - **Consider Diversity:** Use a mix if creating a meta-model (stacking) â€“ e.g., combine a tree model with a Logistic Regression.\n",
        "- **4. Evaluate Performance Using Cross-Validation :**\n",
        "    - **Stratified K-Fold:** Crucial for imbalanced datasets (defaults are rare). Preserves the proportion of defaulters/non-defaulters in each fold.\n",
        "    - **Metrics:**\n",
        "        - **AUC-ROC:** Measures overall classification ability.\n",
        "        - **Precision/Recall/F1-Score:** Essential for imbalanced data; focus on Recall (catching defaulters) or Precision (avoiding false positives) based on business cost.\n",
        "        - **Confusion Matrix:** Visualizes True Positives/Negatives, False Positives/Negatives.\n",
        "- **5. Justify Improved Decision-Making :**\n",
        "    - **Accuracy & Robustness:** Ensembles combine weak learners to form a strong, stable model, reducing reliance on a single model's flaws.\n",
        "    - **Better Risk Assessment:** More accurate predictions mean the bank can better identify high-risk applicants (reducing losses) and potentially approve more good loans (increasing revenue).\n",
        "    - **Actionable Insights:** Probabilities of default (output by ensembles) allow for tiered lending decisions (e.g., higher rates, smaller loans, or denial).\n",
        "    - **Example:** A Random Forest identifies complex patterns (e.g., debt-to-income ratio combined with specific spending habits) missed by simpler models, leading to smarter loan approvals."
      ],
      "metadata": {
        "id": "nxLbCSIJXkRR"
      }
    }
  ]
}